# Мия - виртуальный друг

## Содержание

- [Введение](#)
- [Проблема](#)  
- [Цель и задачи](#) 
- [Целевая аудитория](#)  
- [Исследование аналогов](#) 
- [Новизна](#)  
- [Исследование эмоций человека](#)  
- [Синтез речи](#)  
- [Определение эмоций](#)
- [Языковая модель](#)  
- [Система анализа реакции пользователя на определённые темы сообщений](#)
- [Создание графического интерфейса](#) 
## Введение

  На протяжении всей истории человечества люди стремились к общению и связям с другими людьми. Дружба играет важнейшую роль в нашей жизни, обеспечивая эмоциональную поддержку, компанию людей и источник радости. Однако в нашем быстро меняющемся цифровом мире поддержание крепких человеческих связей может быть сложной задачей.

Этот проект ставит своей целью создать виртуального помощника, который не только будут помогать в повседневных делах и удовлетворять различные потребности, но и сможет выстраивать эмоциональные связи с пользователями. "Виртуальный друг" всегда будет готов поддержать вас, станет вашим собеседником, источником вдохновения и спутником в цифровом мире.
## Проблема
Ощущение одиночества, невозможность открыто высказываться, и социальная изоляция людей оказывают серьезное негативное влияние на их психологическое и эмоциональное благополучие. Когда человек чувствует себя одиноким и изолированным, у него возникает ощущение отсутствия поддержки и понимания со стороны окружающих. Это приводит к недостатку как физического, так и эмоционального общения, что, в свою очередь, усугубляет чувство одиночества и изоляции.

Дефицит общения и эмоциональной поддержки может стать причиной снижения настроения и ухудшения общего состояния человека. Отсутствие возможности выразить свои мысли, чувства и эмоции может привести к накоплению стресса и эмоционального дискомфорта. Это может негативно сказаться на физическом и психическом здоровье, включая нарушения сна, снижение самооценки, а также развитие депрессивных и тревожных расстройств.

Таким образом, отсутствие социальных связей и эмоциональной поддержки может существенно ухудшить качество жизни человека и его общее самочувствие. Это подчеркивает важность общения и получения эмоциональной поддержки, которые являются неотъемлемой частью полноценной жизни.
## Цель и задачи
Цель проекта заключена в создание виртуального друга, который способен взаимодействовать с пользователем. Он будет предоставлять пользователю поддержку, ему поддержку, информацию, развлечение или просто выступая компаньоном для общения. Он также должен понимать и реагировать на эмоциональные состояния пользователя.

Для достижения выше поставленной цели стояли следующие задачи:

- Выделить определённый круг эмоций, которые будет отслеживать программа.

- Поиск или создание модели способной определять эмоции по нужным параметрам.

- Выбор языка программирования.

- Поиск языковый модели подходящей для основы разговорной части.

- Создать систему для анализа реакции пользователя на определённые темы сообщений.

- Создание интуитивно понятного графического интерфейса, для удобства использования.
## Целевая аудитория

Потенциальным пользователем может быть любой человек. Но данный проект в первую очередь рассчитан на людей, чувствующих себя одинокими или нуждающимися в поддержке и компании, но по разным причинам не имеющих возможности общаться с реальными людьми напрямую. Среди них были выделены следящие группы потенциальных пользователей:

-   Люди, испытывающие чувство одиночества и социальной изоляции, независимо от возраста или пола.
-   Те, кто имеет ограниченные возможности для общения в реальной жизни, такие как люди с ограниченными физическими возможностями или мобильностью.
-   Людей, живущих в крупных городах, где уровень стресса и суеты может привести к отчуждению и изоляции.

##	Исследование аналогов

Проведя поиск аналогов и их сравнительный анализ было выделены главные аналоги:

—  Replika — это приложение, разработанное на базе искусственного интеллекта с целью создания виртуального друга. Он предлагает пользователю возможность разговаривать с ИИ, который будет учиться и адаптироваться к его предпочтениям и поведению. Replika ставит целью помочь пользователям вести диалоги, выражать свои эмоции и получать эмоциональную поддержку.

— Woebot — это еще одно приложение с виртуальным помощником, направленным на поддержку психического здоровья. Он использует когнитивно-поведенческую терапию и другие методы, чтобы помочь пользователям справиться с тревогой, депрессией и стрессом. Он предлагает регулярные сеансы и учебные программы для улучшения настроения и управления эмоциями.

— Cleverbot — это один из самых известных чат-ботов, разработанный для имитации разговора с человеком. Cleverbot использует обработку естественного языка, чтобы понимать вопросы и предоставлять ответы. Он не имеет никакой конкретной цели или направления, а просто стремится поддерживать диалог и отвечать на вопросы пользователя.
| Мой проект и аналоги  | Возможность отслеживание эмоций по лицу или голосу |Возможность общаться с использованием голоса | Доступность русского языка|
| :-: | :-: | :-: | :-: |
|  Мия | + | + | + |
| Replika| - | + | - |
| Woebot | - | - | - |
| Cleverbot| - | - | + |

## Новизна

В отличие от большинства существующих виртуальных помощников, ориентированных главным образом на выполнение задач, "Мия" создана для построения эмоциональных отношений с пользователем. Используя технологии голосового общения, распознавания эмоций и обработки естественного языка, она может вести осмысленные диалоги, проявлять сочувствие и отзывчивость, подобно реальному человеку. Это открывает новые возможности для людей в преодолении одиночества и получения эмоциональной поддержки.

## Исследование эмоций человека

Так как человек может проявлять различное множество эмоций и необходимо было выделить основную группу эмоций, которые чаще всего выражают. Для этого я обратился к статье [Basic  Emotions](https://www.researchgate.net/publication/318447136_Basic_Emotions) в которой выделили основные эмоции.

Основные эмоции — это набор эмоций, которые считаются часто используемыми и универсальными для всех людей. Они обычно включают радость, грусть, страх, гнев, удивление и отвращение. Однако есть различные точки зрения на количество и тип основных эмоций, и некоторые исследователи могут предлагать свои собственные списки.

Также человек способен проявлять лживые эмоции. Лживость эмоций, также известная как эмоциональная манипуляция или фальсификация эмоций, возникает, когда человек представляет ложные эмоции или скрывает свои истинные. Это может происходить по разным причинам.

## Синтез речи

Работа синтеза речи заключается в преобразовании текста в аудиофайл с последующим его воспроизведением. Эта функция позволяет виртуальному другу автоматически озвучивать текстовые сообщения, что делает взаимодействие с ним более удобным и естественным для пользователей. Пользователи могут получать ответы в аудио формате, что улучшает доступность сервиса, особенно для тех, у кого есть ограничения в чтении или зрении.

Использование синтеза речи создает более натуральное и приятное восприятие информации. Голосовое воспроизведение текста придает ответам живой характер, делая общение с ним более привлекательным и интересным для пользователей.

Для реализации данной функциональности в проекте была использована библиотека [pyttsx4](https://pypi.org/project/pyttsx4/). Она предоставляет простой и удобный интерфейс для синтеза речи и воспроизведения аудио. Библиотека pyttsx4 основана на платформе Text-to-Speech (TTS) и обладает широкими возможностями настройки, включая выбор различных голосов и параметров синтеза. Это позволяет создавать персонализированные и выразительные голосовые ответы, адаптированные под потребности и предпочтения пользователей.
Пример использования:
```python
import pyttsx4

engine = pyttsx4.init()
engine.say('Привет, как у тебя дела?')
engine.runAndWait()
```

## Определение эмоций
Были определены основные эмоции для отслеживания: радость, грусть, страх, гнев, удивление и отвращение. Выбор этих эмоций обусловлен необходимостью распознавания проявлений соответствующих эмоциональных состояний пользователей, выражаемых с помощью мимики лица и голоса.

Для определения эмоций по лицу используется библиотека fer. Она применяет алгоритмы глубокого обучения, такие как сверточные нейронные сети (CNN), для извлечения признаков из изображений лица и классификации эмоционального состояния. Библиотека способна работать как с отдельными изображениями лиц, так и с видеопотоками и потоковыми данными.

Для определения эмоций по голосу была специально обучена нейронная сеть на датасете Ravdess ([https://paperswithcode.com/dataset/ravdess](https://paperswithcode.com/dataset/ravdess)), достигшая точности 75% в распознавании эмоций. Записанное пользователем голосовое сообщение сохраняется для последующей обработки обученной нейронной сетью, а затем безопасно удаляется.

Таким образом, комбинированное использование распознавания эмоций по лицу и голосу позволяет более точно определять текущее эмоциональное состояние пользователя для более правильной реакции со стороны виртуального собеседника.

Код для распознавания эмоций на лице:
```python
from fer import FER  # Импорт класса FER для обнаружения эмоций на лицах
import cv2  # Импорт библиотеки OpenCV для работы с изображениями

# Создание экземпляра объекта FER для обнаружения эмоций на лицах с использованием MTCNN
detector = FER(mtcnn=True)

# Определение функции для обнаружения эмоций на лицах
def face_emo():
    global face_emotion, face_emotion_score  # Глобальные переменные для хранения эмоции и её оценки

    cap = cv2.VideoCapture(0)  # Захват видеопотока с веб-камеры
    ret, frame = cap.read()  # Получение текущего кадра из видеопотока

    if not ret:
        print("Не удалось получить кадр.")  # Вывод сообщения, если не удалось получить кадр

    emotions = list(detector.top_emotion(frame))  # Обнаружение эмоции на лице в кадре
    face_emotion = emotions[0]  # Получение наиболее вероятной эмоции

    if emotions[1] is not None:
        face_emotion_score = int(emotions[1] * 100)  # Получение оценки эмоции в процентах
    else:
        face_emotion_score = None  # Если оценка не получена, устанавливаем значение None

    cv2.waitKey(30)  # Ожидание для корректного завершения видеопотока
    cap.release()  # Освобождение ресурсов камеры
    cv2.destroyAllWindows()  # Закрытие всех окон OpenCV

    return face_emotion, face_emotion_score  # Возврат эмоции и её оценки
```

Код для обучения модели распознавания эмоций по голосу:
```python
import librosa  # Библиотека для обработки звуковых файлов
import soundfile as sf  # Библиотека для чтения и записи звуковых файлов
import os  # Модуль для работы с операционной системой
import glob  # Модуль для поиска файлов по шаблону
import pickle  # Модуль для сериализации и десериализации объектов Python
import numpy as np  # Библиотека для работы с массивами и матрицами
from sklearn.model_selection import train_test_split, GridSearchCV  # Модули для разделения данных и поиска гиперпараметров
from sklearn.neural_network import MLPClassifier  # Модуль для многослойного перцептрона
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # Модули для оценки модели

# Функция для извлечения признаков (mfcc, chroma, mel) из звукового файла
def extract_feature(file_name, mfcc, chroma, mel):
    with sf.SoundFile(file_name) as sound_file:
        X = sound_file.read(dtype="float32")  # Чтение звукового файла
        sample_rate = sound_file.samplerate  # Частота дискретизации
        result = []  # Инициализация списка для хранения признаков
        if mfcc:
            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)  # Извлечение MFCC
            result.extend(mfccs)  # Добавление MFCC в список признаков
        if chroma:
            stft = np.abs(librosa.stft(X))  # Преобразование Фурье
            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)  # Извлечение хромограммы
            result.extend(chroma)  # Добавление хромограммы в список признаков
        if mel:
            mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)  # Извлечение мел-спектрограммы
            result.extend(mel)  # Добавление мел-спектрограммы в список признаков
    return result   # Возврат списка признаков

# Эмоции в наборе данных RAVDESS
emotions = {
    '03': 'happy', '04': 'sad', '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'
}

# Эмоции для анализа
observed_emotions = list(emotions.values())

# Загрузка данных и извлечение признаков для каждого звукового файла
def load_data(test_size):
    x, y = [], []  # Инициализация списков для хранения признаков и меток
    for file in glob.glob("DataFlair/ravdess data/Actor_*/*.wav"):  # Поиск звуковых файлов в папках
        file_name = os.path.basename(file)  # Извлечение имени файла
        emotion = emotions[file_name.split("-")[2]]  # Извлечение эмоции из имени файла
        if emotion not in observed_emotions:
            continue
        feature = extract_feature(file, mfcc=True, chroma=True, mel=True)  # Извлечение признаков из файла
        x.append(feature)  # Добавление признаков в список x
        y.append(emotion)  # Добавление эмоции в список y
    return train_test_split(np.array(x), y, test_size=test_size, random_state=10)  # Разделение данных на обучающий и тестовый наборы

# Разделение набора данных
x_train, x_test, y_train, y_test = load_data(test_size=0.25)

# Инициализация классификатора многослойного перцептрона
model = MLPClassifier()

# Определение гиперпараметров для поиска
parameters = {
    'alpha': [0.0001, 0.001, 0.01],
    'batch_size': [8, 16, 32],
    'epsilon': [1e-08, 1e-06, 1e-05],
    'hidden_layer_sizes': [(100,), (200,), (300,)],
    'max_iter': [1000, 1500, 2000]
}

# Поиск гиперпараметров с использованием сетки
grid_search = GridSearchCV(model, parameters, n_jobs=-1, cv=5)
grid_search.fit(x_train, y_train)

# Получение лучшей модели из поиска по сетке
best_model = grid_search.best_estimator_

# Прогнозирование для тестового набора данных с использованием лучшей модели
y_pred = best_model.predict(x_test)

# Вычисление точности лучшей модели
accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)
print("Accuracy: {:.2f}%".format(accuracy * 100))

# Печать дополнительных метрик
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Сохранение обученной модели в файл
with open('emotion_classifier_model.pkl', 'wb') as model_file:
    pickle.dump(best_model, model_file)
```

## Языковая модель

Языковая модель — это компонент, который позволяет программе понимать текст, написанный пользователем, и формировать осмысленные ответы.

Когда пользователь вводит сообщение, модель анализирует его, распознавая отдельные слова, фразы и контекст. Она пытается определить намерение пользователя - что он хочет узнать, сделать или обсудить.

Затем модель генерирует текстовый ответ, используя свои "знания" о грамматике, смысле слов и правилах построения предложений. Она старается составить грамотный, связный и уместный в данном контексте ответ.

Если модель чего-то не понимает, она может задать уточняющие вопросы, запросить больше информации или попросить пользователя переформулировать свой запрос.

Обученная на большом количестве текстов, языковая модель позволяет вести достаточно естественный диалог, приближенный к общению между людьми. Это создает ощущение "разумности" у собеседника.

Было проведено сравнение доступных языковых моделей учитывая такие критерии, как:

- Производительность

- Оптимизация для вывода

- Открытый исходный код

И среди всех была выбрана такая модель как OpenChat-3.5-0106 ([https://github.com/imoneoi/openchat](https://github.com/imoneoi/openchat)).
![img](https://raw.githubusercontent.com/imoneoi/openchat/master/assets/openchat-bench-0106.png)
_Изображение взято с [официального репозитория](https://github.com/imoneoi/openchat)_)

Пример кода для использования модели:
```python
from transformers import AutoTokenizer, AutoModelForCausalLM  # Импорт необходимых классов из библиотеки Transformers

# Загрузка предобученного токенизатора и модели языковой модели
tokenizer = AutoTokenizer.from_pretrained("openchat/openchat-3.5-0106")  
model = AutoModelForCausalLM.from_pretrained("openchat/openchat-3.5-0106") 

# Сообщение от пользователя
messages = [
    {"role": "user", "content": f"Привет как у тебя дела?"}  
]

# Подготовка входных данных для модели
model_inputs = tokenizer.apply_chat_template(messages, return_tensors="pt")

# Генерация ответа от модели
generated_ids = model.generate(model_inputs, max_new_tokens=100, do_sample=True)  

# Декодирование сгенерированного текста и печать ответа
print(tokenizer.batch_decode(generated_ids)[0]) 
```

## Система анализа реакции пользователя на определённые темы сообщений

Для того чтобы языковая модель лучше понимала какие темы стоит избегать или чаще упоминать при общении необходимо классифицировать сообщения и анализировать реакцию пользователя на них, для того чтобы понять какие темы стоит избегать, а какие стоит упоминать чаще при определённых ситуациях.

Для классификации сообщений и анализа реакции пользователя на них были выделены следующие темы:

1. Нейтральные темы (общие разговоры, новости, погода и т.д.)

2. Личные темы (семья, увлечения, работа и т.д.)

3. Эмоционально окрашенные темы (политика, религия, спорные вопросы и т.д.)

4. Темы, связанные с чувствительной информацией (финансы, здоровье, личные данные и т.д.)

5. Запрещенные темы (нелегальная деятельность, оскорбления, насилие и т.д.)

6. Позитивные темы (достижения, успехи, радостные события и т.д.)

7. Негативные темы (проблемы, трудности, потери и т.д.)

8. Развлекательные темы (юмор, игры, развлечения и т.д.)

9. Образовательные темы (наука, технологии, обучение и т.д.)

10. Темы, связанные с продуктами или услугами (реклама, маркетинг и т.д.)

Анализируя реакцию пользователя на каждый из этих типов тем, можно определить, какие из них стоит избегать или упоминать чаще в зависимости от ситуации и контекста общения. И данная система работает по такому плану:

1. Классифицировать входящие сообщения по заранее определенным категориям тем.

2. Отслеживать и анализировать реакцию пользователя на каждое сообщение, относящееся к той или иной категории тем.

3. На основе анализа реакций пользователя определять, какие категории тем вызывают положительную реакцию (интерес, вовлеченность, продолжение диалога), а какие - отрицательную реакцию (неудовольствие, отторжение, прекращение диалога).

4. Адаптировать поведение языковой модели в соответствии с полученными данными, избегая упоминания тем, вызывающих отрицательную реакцию, и чаще упоминая темы, вызывающие положительную реакцию, в зависимости от ситуации и контекста общения.

5. Постоянно обновлять и совершенствовать систему анализа на основе новых данных, полученных в ходе взаимодействия с пользователями, для более точного определения предпочтительных и нежелательных тем.

Такая система анализа реакции пользователя на определенные темы сообщений позволит языковой модели адаптироваться к индивидуальным предпочтениям пользователей и обеспечить более эффективное и приятное взаимодействие.

## Создание графического интерфейса
При создании графического интерфейса использовалась библиотека eel. Она обеспечивает простой способ интеграции Python с веб-технологиями HTML/CSS/JavaScript для построения интерфейса. Благодаря eel можно создавать кроссплатформенные десктопные приложения, которые могут использовать все возможности браузера.

Пример работы прототипа:

![video](https://github.com/pocketgodru/MIA-chatbot/assets/126785140/176a0581-6188-47c8-96bc-badefc533122)

> На данный момент не все функции добавленны в интерфейс, они находятся на стадии доработки и внедрения
